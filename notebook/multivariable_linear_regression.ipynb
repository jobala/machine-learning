{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599543905429",
   "display_name": "Python 3.8.5 64-bit ('experiments': pipenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariable Linear Regression\n",
    "\n",
    "In this tutorial we will implement multivariable linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   area  rooms   price\n0  2104      3  399900\n1  1600      3  329900\n2  2400      3  369000\n3  1416      2  232000\n4  3000      4  539900",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>area</th>\n      <th>rooms</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2104</td>\n      <td>3</td>\n      <td>399900</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1600</td>\n      <td>3</td>\n      <td>329900</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2400</td>\n      <td>3</td>\n      <td>369000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1416</td>\n      <td>2</td>\n      <td>232000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3000</td>\n      <td>4</td>\n      <td>539900</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipywidgets import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('../data/house_prices_2.csv')\n",
    "\n",
    "training_data = df.head() \n",
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Before using the training data, we should make it easy to work with. The values for area, rooms and price are spread over different ranges and as a consequence gradient descent will need to run for longer, over many iterations before finding the optimal values for parameters $\\theta$. We can have the data spread out over approximately the same range by  **scaling and normalizing** the input variables.\n",
    "\n",
    "#### Feature Scaling And Mean Normalization\n",
    "Feature scaling involves dividing the input variable with the range -- difference between max and min values or the standard deviation and mean normalization involves substracting the mean from the input variable.\n",
    "\n",
    "The formula below scales and normalizes features.\n",
    "\n",
    "$x_i = \\frac{x_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "Where $\\mu_i$ is the mean and $\\sigma_i$ is the range or standard deviation for the ith feature. In this tutorial, we'll use standard deviation instead of range for $\\sigma_i$\n",
    "\n",
    "**Example**\n",
    "\n",
    "Scale and normalize area's first entry\n",
    "\n",
    "$\\mu_i = 2104$\n",
    "\n",
    "$\\sigma_i = 568.82$\n",
    "\n",
    "norm_area $= \\frac{2104 - 2104}{568.83}$\n",
    "\n",
    "Therefore, norm_area $=$ 0\n",
    "\n",
    "The snippet below implements the formula in Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input_variables):\n",
    "    result = None\n",
    "\n",
    "    mean = np.mean(input_variables)\n",
    "    std = np.std(input_variables)\n",
    "\n",
    "    result = (input_variables - mean) / std\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can normalize the input variables, area and rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       area     rooms   price\n0  0.000000  0.000000  399900\n1 -0.886042  0.000000  329900\n2  0.520374  0.000000  369000\n3 -1.209517 -1.581139  232000\n4  1.575185  1.581139  539900",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>area</th>\n      <th>rooms</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>399900</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.886042</td>\n      <td>0.000000</td>\n      <td>329900</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.520374</td>\n      <td>0.000000</td>\n      <td>369000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.209517</td>\n      <td>-1.581139</td>\n      <td>232000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.575185</td>\n      <td>1.581139</td>\n      <td>539900</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "area = training_data['area']\n",
    "rooms = training_data['rooms']\n",
    "\n",
    "training_data['area'] = normalize(area)\n",
    "training_data['rooms'] = normalize(rooms)\n",
    "\n",
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "\n",
    "[Linear regression](https://buffered.dev/linear-regression/) used an iterative technique to compute the gradient descent. While that worked it's not as fast and simple as the vectorized implementation.\n",
    "\n",
    "\n",
    "## Hypothesis\n",
    "The formular for the hypothesis function with n features is as shown below\n",
    "\n",
    "$h(x) = \\sum_{0}^{n}\\theta_j x_j$\n",
    "\n",
    "Which is the same as \n",
    "\n",
    "$h(x) = \\theta_0 + \\theta_1 x_1 ... \\theta_n x_n$ \n",
    "\n",
    "The equation above is equivalent to a matrix vector dot product\n",
    "\n",
    "$h(x) = X \\cdot \\theta$\n",
    "\n",
    "#### Example\n",
    "\n",
    "Describing the input variables as a matrix, I will add ones to the first column to make computation easy.\n",
    "\n",
    "$\n",
    "X = \\begin{bmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "1 & -0.9 & 0 \\\\\n",
    "1 & 0.5 & 0 \\\\\n",
    "1 & -1.2 & -1.6 \\\\\n",
    "1 & 1.6 & 1.6 \\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "Then we can describe parameters $\\theta$ as a vector -- using arbitrary values for $\\theta$\n",
    "\n",
    "$\n",
    "\\theta = \\begin{bmatrix}\n",
    "0 \\\\\n",
    "1 \\\\\n",
    "2 \\\\\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "Then prediction $ = X \\cdot \\theta $\n",
    "\n",
    "$ X \\cdot \\theta = \\begin{bmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "1 & -0.9 & 0 \\\\\n",
    "1 & 0.5 & 0 \\\\\n",
    "1 & -1.2 & -1.6 \\\\\n",
    "1 & 1.6 & 1.6 \\\\\n",
    "\\end{bmatrix} \\cdot \\begin{bmatrix}\n",
    "0 \\\\\n",
    "1 \\\\\n",
    "2 \\\\\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Therefore\n",
    "\n",
    "$prediction = X \\cdot \\theta = \\begin{bmatrix}\n",
    "0.0 \\\\\n",
    "-0.9 \\\\\n",
    "-4.4 \\\\\n",
    "4.8 \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Writing the hypothesis algorithm in Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(X, theta):\n",
    "    return X @ theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function\n",
    "\n",
    "The formular for unvectorized cost function is\n",
    "\n",
    "$J(\\theta) = \\frac{1}{2m}\\sum_{1}^{m}(h(x_i) - y_i)^2$\n",
    "\n",
    "The vectorized equivalient of $(h(x_i) - y_i)^2$ is $(X \\cdot \\theta - y)^T \\times (X \\cdot \\theta - y)$\n",
    "\n",
    "So the vectorized cost function can be written as \n",
    "\n",
    "$J(\\theta) = \\frac{1}{2m}sum((X \\cdot \\theta - y)^T \\times (X \\cdot \\theta - y))$\n",
    "\n",
    "Since $X \\cdot \\theta = prediction $, we can use the hypothesis function when implementing the cost function in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(X, theta, y):\n",
    "    m, _ = X.shape\n",
    "\n",
    "    sqdError = np.matmul(np.transpose(hypothesis(X, theta) - y),  (hypothesis(X, theta) -y))\n",
    "        \n",
    "    return (1/(2 * m)) * np.sum(sqdError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "75022811342.346"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "X = np.array([\n",
    "      [1.0,  0.0,  0.0],\n",
    "      [1.0, -0.9,  0.0],\n",
    "      [1.0,  0.5,  0.0],\n",
    "      [1.0, -1.2, -1.6],\n",
    "      [1.0,  1.6,  1.6]\n",
    "      ])\n",
    "theta = np.array([\n",
    "    0,\n",
    "    1, \n",
    "    2\n",
    "   ])\n",
    "y = np.array([\n",
    "   399900,\n",
    "   329900,\n",
    "   369000,\n",
    "   232000,\n",
    "   539900])\n",
    "   \n",
    "cost = cost_function(X, theta, y)\n",
    "cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "The unvectorized formular for gradient descent is as shown below\n",
    "\n",
    "repeat until covergence {\n",
    "\n",
    "$\\theta = \\theta - \\alpha \\frac{1}{m}\\sum_{1}^{m}(h(x_i) - y_i)x_i$\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "And the vectorized formular \n",
    "\n",
    "repeat until convergence {\n",
    "\n",
    "$\\theta_i = \\theta_i - \\alpha \\frac{1}{m}sum((X \\cdot \\theta - y)x_i)$\n",
    "\n",
    "}\n",
    "\n",
    "The snippet below implements gradient descent in Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, theta, alpha=0, num_iter=1):\n",
    "    m, features = X.shape\n",
    "    temp = np.zeros(shape=(theta.shape))\n",
    "\n",
    "    for i in range(0, num_iter):\n",
    "        for feature in range(0, features):\n",
    "            temp[feature] = theta[feature] - (alpha / m ) * np.sum(((X @ theta) - y) * X[:, feature])\n",
    "        theta = temp\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running gradient descent, we get the following values for the parameters $\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([-2.47154393e+268, -4.65254066e+284,  1.19688093e+286])"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "thetas = gradient_descent(X, theta, alpha=30, num_iter=100)\n",
    "thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}